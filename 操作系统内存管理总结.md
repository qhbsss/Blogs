[TOC]
# 虚拟内存

把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「**虚拟地址**」，人人都有，大家自己玩自己的地址就行，互不干涉。但是有个前提每个进程都不能访问物理地址，至于虚拟地址最终怎么落到物理内存里，对进程来说是透明的，操作系统已经把这些都安排的明明白白了。

![进程的中间层](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Pictures298fb68e3da94d767b02f2ed81ebf2c4.png)

**操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**

如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。

于是，这里就引出了两种地址的概念：

- 我们程序所使用的内存地址叫做**虚拟内存地址**（*Virtual Memory Address*）
- 实际存在硬件里面的空间地址叫**物理内存地址**（*Physical Memory Address*）。

操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：

![](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_PicturesBlog_Pictures72ab76ba697e470b8ceb14d5fc5688d9.png)

# 内存碎片

内存碎片是由内存的申请和释放产生的，通常分为下面两种：

- **内部内存碎片(Internal Memory Fragmentation，简称为内存碎片)**：已经分配给进程使用但未被使用的内存。导致内部内存碎片的主要原因是，当采用固定比例比如 2 的幂次方进行内存分配时，进程所分配的内存可能会比其实际所需要的大。举个例子，一个进程只需要 65 字节的内存，但为其分配了 128（2^7） 大小的内存，那 63 字节的内存就成为了内部内存碎片。
- **外部内存碎片(External Memory Fragmentation，简称为外部碎片)**：由于未分配的连续内存区域太小，以至于不能满足任意进程所需要的内存分配请求，这些小片段且不连续的内存空间被称为外部碎片。也就是说，外部内存碎片指的是那些并未分配给进程但又不能使用的内存。我们后面介绍的分段机制就会导致外部内存碎片。

![内存碎片](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesinternal-and-external-fragmentation.png)

内存管理方式可以简单分为下面两种：

- **连续内存管理**：为**一个用户程序**分配一个连续的内存空间，内存利用率一般不高。
- **非连续内存管理**：允许**一个程序**使用的内存分布在离散或者说不相邻的内存中，相对更加灵活一些。

>linux整体上采用非连续内存的管理的段页式内存管理方式，但当内核需要连续的物理内存时，伙伴系统会尝试分配连续的块，但这只是内存管理的一个方面，而不是Linux整体内存管理的基础。

## 连续内存管理

**块式管理** 是早期计算机操作系统的一种连续内存管理方式，存在严重的内存碎片问题。块式管理会将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为内部内存碎片。除了内部内存碎片之外，由于两个内存块之间可能还会有外部内存碎片，这些不连续的外部内存碎片由于太小了无法再进行分配。

**动态分区分配策略：**

- 最先匹配：最先找到哪个满足条件的空闲分区就把进程分区放进去（一般性能最好）
- 最佳匹配：找最佳的空闲分区 ，使得空闲分区大小和进程分区大小接近
- 最差匹配：每次用的空闲分区都是最大的。

在操作系统层面，Linux系统使用伙伴系统Buddy分配器以页为单位来组织物理内存页框，对物理内存页进行合理的分配和回收，让内存分配与相邻内存合并能快速进行，用于缓解外部内存碎片，同时为了减少内部碎片，Linux还引入了slab算法，将内存页拆分为更小的单位来管理，slab可以对小对象空间进行分配，而不需要分配整个页面给对象，这样可以节省空间，内核中对于频繁使用的小对象，slab还会对此作缓存，避免频繁的内存分配和回收。

在 Linux 系统中，连续内存管理采用了 **伙伴系统（Buddy System）算法** 来实现，这是一种经典的连续内存分配算法，可以有效解决外部内存碎片的问题。伙伴系统的主要思想是将内存按 2 的幂次划分（每一块内存大小都是 2 的幂次比如 2^6=64 KB），并将相邻的内存块组合成一对伙伴（注意：**必须是相邻的才是伙伴**）。

> 伙伴系统工作在页式内存管理的基础之上
Linux使用分页机制管理物理内存的，把所有的空闲页分组为11个块链表，每个块链表分别包含大小为1，2，4，8，16，32，64，128，256，512和1024个连续页框的页块（2^0 ~ 2^10，页阶order从0-10）。最大可以申请1024个连续页，对应4MB大小的连续内存（待验证下）。每个页块的第一个页的物理地址是该块大小的整数倍。
Linux中的伙伴系统是以页面为最小单位分配的，工作机制如下：
当内核申请页阶为n的页块时，伙伴系统会先从块链表n中查找是否有空闲页；
如果没有则从大一阶的页块中查找（没找到继续往大页链表中找）；
找到后，将大页阶进行对半切割，一半用于内存分配，另一半放到对应页阶的空闲链表中，同时设置伙伴标记。）

当进行内存分配时，伙伴系统会尝试找到大小最合适的内存块。如果找到的内存块过大，就将其一分为二，分成两个大小相等的伙伴块。如果还是大的话，就继续切分，直到到达合适的大小为止。

假设两块相邻的内存块都被释放，系统会将这两个内存块合并，进而形成一个更大的内存块，以便后续的内存分配。这样就可以减少内存碎片的问题，提高内存利用率。

![伙伴系统（Buddy System）内存管理](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Pictureslinux-buddy-system.png)

虽然解决了外部内存碎片的问题，但伙伴系统仍然存在内存利用率不高的问题（内部内存碎片）。这主要是因为伙伴系统只能分配大小为 2^n 的内存块，因此当需要分配的内存大小不是 2^n 的整数倍时，会浪费一定的内存空间。举个例子：如果要分配 65 大小的内存快，依然需要分配 2^7=128 大小的内存块。

![伙伴系统内存浪费问题](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesbuddy-system-memory-waste.png)

对于内部内存碎片的问题，Linux 采用 **SLAB** 进行解决。
内核中对内存页的分配使用有两种方式，一种是一页一页的分配使用，这种以页为单位的分配方式内核会向相应内存区域zone里的伙伴系统申请以及释放。
另一种方式就是只分配小块的内存，不需要一下分配一页的内存，比如前边章节中提到的struct page ,anon_vma_chain , anon_vma ,vm_area_struct结构实例的分配，这些结构通常就是几十个字节大小，并不需要按页来分配。
为了满足类似这种小内存分配的需要，Linux内核使用slab allocator分配器来分配，slab就好比一个对象池，内核中的数据结构对象都对应于一个slab对象池，用于分配这些固定类型对象所需要的内存。
它的基本原理是从伙伴系统中申请一整页内存，然后划分成多个大小相等的小块内存被slab所管理。这样一来slab就和物理内存页page 发生了关联，由于slab管理的单元是物理内存页page内进一步划分出来的小块内存，所以当page被分配给相应slab结构之后，struct page里也会存放slab相关的一些管理数据。

## 非连续内存管理

非连续内存管理存在下面 3 种方式：

- **段式管理**：以段(—段连续的物理内存)的形式管理/分配物理内存。应用程序的虚拟地址空间被分为大小不等的段，段是有实际意义的，每个段定义了一组逻辑信息，例如有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。
- **页式管理**：把物理内存分为连续等长的物理页，应用程序的虚拟地址空间也被划分为连续等长的虚拟页，是现代操作系统广泛使用的一种内存管理方式。
- **段页式管理机制**：结合了段式管理和页式管理的一种内存管理机制，把物理内存先分成若干段，每个段又继续分成若干大小相等的页。

# 内存管理方式
## 内存分段
程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。**不同的段是有不同的属性的，所以就用分段（*Segmentation*）的形式把这些段分离出来。**

### 分段机制下，虚拟地址和物理地址的映射关系

分段机制下的虚拟地址由两部分组成，**段选择因子**和**段内偏移量**。

![](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesa9ed979e2ed8414f9828767592aadc21.png)

段选择因子和段内偏移量：

- **段选择因子**就保存在段寄存器里面。段选择因子里面最重要的是**段号**，用作段表的索引。**段表**里面保存的是这个**段的基地址、段的界限和特权等级**等。

- 虚拟地址中的**段内偏移量**应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。

在上面，知道了虚拟地址是通过**段表**与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：

![](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesc5e2ab63e6ee4c8db575f3c7c9c85962.png)

### 分段的不足之处：
1. #### 内存碎片
内存分段管理可以做到段根据实际需求分配内存，所以有多少需求就分配多大的段，所以**不会出现内部内存碎片**。
但是由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以**会出现外部内存碎片**的问题。
解决「外部内存碎片」的问题就是**内存交换**。
2. #### 内存交换的效率低
对于多进程的系统来说，用分段的方式，外部内存碎片是很容易产生的，产生了外部内存碎片，那不得不重新 `Swap` 内存区域，这个过程会产生性能瓶颈。
因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。
所以，**如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。**

## 内存分页

分段的好处就是能产生连续的内存空间，但是会出现「外部内存碎片和内存交换的空间太大」的问题。

要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是**内存分页**（*Paging*）。

**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。这样一个连续并且尺寸固定的内存空间，我们叫**页**（*Page*）。在 Linux 下，每一页的大小为 `4KB`。

虚拟地址与物理地址之间通过**页表**来映射，如下图：

![](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Pictures08a8e315fedc4a858060db5cb4a654af.png)


页表是存储在内存里的，**内存管理单元** （*MMU*）就做将虚拟内存地址转换成物理地址的工作。

而当进程访问的虚拟地址在页表中查不到时，系统会产生一个**缺页异常**，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。

### 分页机制下，虚拟地址和物理地址的映射关系

在分页机制下，虚拟地址分为两部分，**页号**和**页内偏移**。页号作为页表的索引，**页表**包含物理页每页所在**物理内存的基地址**，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。

![](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Pictures7884f4d8db4949f7a5bb4bbd0f452609.png)

总结一下，对于一个内存地址转换，其实就是这样三个步骤：

- 把虚拟内存地址，切分成页号和偏移量；
- 根据页号，从页表里面，查询对应的物理页号；
- 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。

下面举个例子，虚拟内存中的页通过页表映射为了物理内存中的页，如下图：

![](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Pictures8f187878c809414ca2486b0b71e8880e.png)
#### 多级页表
简单的分页有空间上的缺陷，因为操作系统是可以同时运行非常多的进程的，这就意味着页表会非常的庞大。要解决上面的问题，就需要采用一种叫作**多级页表**（*Multi-Level Page Table*）的解决方案。

在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 `4KB` 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。

我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 `1024` 个页表（二级页表），每个表（二级页表）中包含 `1024` 个「页表项」，形成**二级分页**。如下图所示：

![](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Pictures19296e249b2240c29f9c52be70f611d5.png)

根据计算机组成原理里面无处不在的**局部性原理**，**如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表**。

从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以**页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项**（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。

把二级分页再推广到多级页表，就会发现页表占用的内存空间更少了，这一切都要归功于对局部性原理的充分应用。

对于 64 位的系统，两级分页肯定不够了，就变成了四级目录，分别是：

- 全局页目录项 PGD（*Page Global Directory*）；
- 上层页目录项 PUD（*Page Upper Directory*）；
- 中间页目录项 PMD（*Page Middle Directory*）；
- 页表项 PTE（*Page Table Entry*）；

![](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Pictures%E5%9B%9B%E7%BA%A7%E5%88%86%E9%A1%B5.png)


#### TLB

多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。

程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。

![](https://img-blog.csdnimg.cn/edce58534d9342ff89f5261b1929c754.png)


我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（*Translation Lookaside Buffer*） ，通常称为页表缓存、转址旁路缓存、快表等。

![](https://img-blog.csdnimg.cn/a3cdf27646b24614a64cfc5d7ccffa35.png)

在 CPU 芯片里面，封装了内存管理单元（*Memory Management Unit*）芯片，它用来完成地址转换和 TLB 的访问与交互。

有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。

TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。

### 内存分页的优缺点

内存分页由于内存空间都是预先划分好的，也就不会像内存分段一样，在段与段之间会产生间隙非常小的内存，这正是分段会产生外部内存碎片的原因。而**采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。**

但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对**内存分页机制会有内部内存碎片**的现象。

如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为**换出**（*Swap Out*）。一旦需要的时候，再加载进来，称为**换入**（*Swap In*）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，**内存交换的效率就相对比较高。**

![](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Pictures388a29f45fe947e5a49240e4eff13538.png)


更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是**只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。**

# 内存分配方式
## Linux内存布局
在 Linux 操作系统中，虚拟地址空间的内部又被分为**内核空间和用户空间**两部分，不同位数的系统，地址空间的范围也不同。比如最常见的 32 位和 64 位系统，如下所示：

![图片](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Pictures1db038e1d2e5325b05e2bb80475d962a.png)



通过这里可以看出：

- `32` 位系统的内核空间占用 `1G`，位于最高处，剩下的 `3G` 是用户空间；
- `64` 位系统的内核空间和用户空间都是 `128T`，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。

虽然每个进程都各自有独立的虚拟内存，但是**每个虚拟内存中的内核地址，其实关联的都是相同的物理内存**。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。

![图片](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesc88bda5db60029f3ea57e4306e7da936.png)



用户空间和内核空间划分的方式是不同的，用户空间内存从**低到高**分别是 6 种不同的内存段：

![图片](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Pictures7b5b6b3728acde8df019350df3cb85c1.png)



- 程序文件段，包括二进制可执行代码；
- 已初始化数据段，包括静态常量；
- 未初始化数据段，包括未初始化的静态变量；
- 堆段，包括动态分配的内存，从低地址开始向上增长；
- 文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关）；
- 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 `8 MB`。当然系统也提供了参数，以便我们自定义大小；

在这 6 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 `malloc()` 或者 `mmap()` ，就可以分别在堆和文件映射段动态分配内存。

## malloc

malloc() 并不是系统调用，而是 C 库里的函数，用于动态分配内存。**malloc() 分配的是虚拟内存**。如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的，这样就不会占用物理内存了。只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存和物理内存之间的映射关系。

malloc 申请内存的时候，会有两种方式向操作系统申请堆内存。
### brk()
通过 brk() 系统调用从堆分配内存,如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；
通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间。如下图：

![](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesbrk%E7%94%B3%E8%AF%B7.png)

malloc 通过 **brk()** 方式申请的内存，free 释放内存的时候，**并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用**.
#### brk()优缺点
- 优点：
malloc 通过 brk() 系统调用在堆空间申请内存的时候，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放的时候，就缓存在内存池中。等下次在申请内存的时候，就直接从内存池取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还存在，这样不仅减少了系统调用的次数，也减少了缺页中断的次数，这将大大降低 CPU 的消耗。
- 缺点：
随着系统频繁地 malloc 和 free，尤其对于小块内存，堆内将产生越来越多不可用的碎片，导致“内存泄露”。而这种“泄露”现象使用 valgrind 是无法检测出来的。
### mmap()
通过 mmap() 系统调用在文件映射区域分配内存；如果用户分配的内存大于 128 KB，则通过 mmap()  申请内存；
通过 mmap() 系统调用中「私有匿名映射」的方式，在文件映射区分配一块内存，也就是从文件映射区“偷”了一块内存。如下图：

![](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesmmap%E7%94%B3%E8%AF%B7.png)

malloc 通过 **mmap()** 方式申请的内存，free 释放内存的时候，**会把内存归还给操作系统，内存得到真正的释放**。
#### mmap()优缺点
- 优点：
分配大内存，不会产生内存泄露
- 缺点：
**频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大**
