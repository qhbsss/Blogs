[TOC]



# cpu

## 计算能力是怎么来的

![image-20241103173900884](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241103173900884.png)

无论程序员编写的程序多么复杂，软件承载的功能最终都是通过这个晶体管简单的开闭完成的  

现在有了晶体管，也就是开关，在此基础之上就可以搭积木了，你随手搭建出来这样三种组合：

- 两个开关只有同时打开电流才会通过，灯才会亮

- 两个开关中只要有一个打开电流就能通过，灯就会亮

- 当开关关闭时电流通过灯会亮，打开开关灯反而电流不能通过灯会灭

上述组合分别就是：与门，AND Gate、或门，OR gate、非门，NOT gate

给定足够的AND、OR以及NOT门，就可以实现任何一个逻辑函数，除此之外我们不需要任何其它类型的逻辑门电路，这时我们认为{AND、OR、NOT}就是逻辑完备的。  

## 神奇的记忆能力

电路怎么能保存信息呢？这个电路有记忆功能  

![image-20241103174123097](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241103174123097.png)

这是两个NAND门的组合，不要紧张，NAND也是设计的与或非门组合而成的，所谓NAND门就是与非门，先与然后取非  

比较独特的是该电路的组合方式，**一个**NAND**门的输出是两一个**NAND**门的输入**，该电路的组合方式会生成一种很有趣的特性，**只要给**S**和**R**段输入**1**，那么这个电路只会有两种状态**:

- 要么a端为1，此时B=0、A=1、b=0；

- 要么a端为0，此时B=1、A=0、b=1;

不会再有其他可能了，**我们把**a**端的值作为电路的输出**。

现在为保存信息你需要同时设置S端和R端，但你的输入是有一个，为此你对电路进行了简答的改造：  

![image-20241103174318352](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241103174318352.png)

当D为0时，整个电路保存的就是0，否则就是1。  

## 指令集

指令集告诉我们 CPU 可以执行什么指令，每种指令需要提供什么样的操作数。不同类型的CPU会有不同的指令集。  

## 指挥家

现在我们的电路有了计算功能、存储功能，还可以通过指令告诉该电路执行什么操作，还有一个问题没有解决。  这个问题就是靠什么来协调靠什么来同步各个部分让它们协同工作呢？  假设我们要计算1+1，这两个数分别来自寄存器R1 和 R2，要知道寄存器中可以保存任意值，我们怎么能确保加法器开始工作时R1****R2中在这一时刻保存的都是1而不是其它数？ 

负责指挥角色的就是时钟信号。时钟信号就像指挥家手里的拿的指挥棒，**指挥棒挥动一下整个乐队会整齐划一的有个相应动作**，同样的，在时钟信号的每一次电压改变，整个电路中的各个寄存器(也就是整个电路的状态)会更新一下，这样我们就能确保整个电路协同工作不会这里提到的问题。

CPU的主频是说一秒钟指挥棒挥动了多少次，当然主频越高CPU在一秒内完成的操作也就越多  

# 进程与线程

## 同步调用

### 同一个线程间的同步调用

一般的函数调用都是同步的，就像这样：  

```
funcA() {
    // 等待函数funcB执行完成
    funcB();
    // 继续接下来的流程
}
```

funcA调用funcB，那么在funcB执行完前，funcA中的后续代码都不会被执行，也就是说funcA必须**等待**funcB执行完成，就像这样：  

![image-20241103191308388](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241103191308388.png)

一般来说，像这种同步调用，funcA和funcB是运行在同一个线程中的，这是最为常见的情况。  

### 不同线程间的同步调用

但值得注意的是，即使运行在两个不能线程中的函数也可以进行同步调用，像进行IO操作时实际上底层是通过系统调用的方式向操作系统发出请求的，比如磁盘文件读取：  

```
read(file, buf);
```

阻塞式I/O，在read函数返回前程序是无法继续向前推进的  

```
read(file, buf);
// 程序暂停运行，
// 等待文件读取完成后继续运行
```

![image-20241103191508337](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241103191508337.png)

只有当read函数返回后程序才可以被继续执行。

当然，这也是同步调用，但是和上面的同步调用不同的是，函数和被调函数运行在不同的线程中。

>同步调用和函数与被调函数是否运行在同一个线程是没有关系的。  

## 异步调用

以磁盘文件读取为例。在函数的同步调用方式下，文件读取完之前调用方是无法继续向前推进的，但如果read函数可以异步调用情况就不一样了。

假如read函数可以异步调用的话，即使文件还没有读取完成，read函数也可以立即返回。

```
read(file, buff);
// read函数立即返回
// 不会阻塞当前程序
```

![image-20241103191637601](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241103191637601.png)

在异步这种调用方式下，调用方不会被阻塞，函数调用完成后可以**立即**执行接下来的程序。

这时异步的重点就在于调用方接下来的程序执行可以和文件读取**同时**进行，从上图中我们也能看出这一点，这就是异步的高效之处。

> 现代磁盘想内存copy数据时无需借助CPU的帮助，这就是所谓的DMA(Direct Memory Access)  

### 异步调用感知方式

在同步调用下，调用方不再继续执行而是暂停等待，被调函数执行完后很自然的就是调用方继续执行，那么异步调用下调用方怎知到被调函数是否执行完成呢？  

这就分为了两种情况：

1. 调用方根本就不关心执行结果

2. 调用方后续需要知道执行结果

第一种情况比较简单，该情况无需讨论。

第二种情况下就比较有趣了，通常有两种实现方式：

一种是通知机制，也就是说当任务执行完成后发送信号用来通知调用方任务完成，注意这里的信号就有很多实现方式了，Linux中的signal，或者使用信号量等机制都可以实现。

另一种是就是回调，也就是我们常说的callback

>eg:
>
>假定处理一次用户请求需要经过步骤A、B、C然后读取数据库，数据库读取完成后需要经过步骤D、E、F.
>
> 一个请求需要经过七个步骤，其中前三个是在主线程中完成的，后四个是在数据库线程中完成的，那么数据库线程是怎么知道查完数据库后要处理D、E、F这几个步骤呢？  
>
>将D、E、F这几个步骤封装到第一个函数中，我们将该函数命名为handle_DEF_after_DB_query:  
>
>```
>void handle_DEF_after_DB_query () {
>        D;
>        E;
>        F;
>}
>```
>
>这样主线程在发送数据库查询请求时将该函数一并当做参数传递过去：  
>
>```
>DB_query(request, handle_DEF_after_DB_query);
>```
>
>数据库线程处理完查询后直接调用handle_DEF_after_DB_query就可以了，这就是回调函数的作用。
>
>也有的同学可能会有疑问，为什么这个函数要传递给数据库线程而不是数据库线程自己定义自己调用呢？
>
>因为从软件组织结构上讲，这不是数据库线程该做的工作。
>
>数据库线程需要做的仅仅就是查询数据库、然后调用一个处理函数，
>
>**至于这个处理函数做了些什么数据库线程根本就不关心，也不应该关心**。
>
>你可以传入各种各样的回调函数。也就是说数据库系统可以针对回调函数这一抽象的函数变量来编程，从而更好的应对变化，因为回调函数的内容改变不会影响到数据库线程的逻辑，而如果数据库线程自己定义处理函数那么这种设计就没有灵活性可言了。
>
>而从软件开发的角度看，假设数据库线程逻辑是其它团队研发的，并用作库提供给其它团队，当数据库团队在研发时怎么可能知道数据库查询后该怎么处理呢，因此该团队在编写代码时简单的使用一个回调函数即可。
>
>与此同时，显然只有使用方才知道查询完数据库后该做些什么，因此使用方在使用时简单的传入这个回调函数就可以了。
>
>这样数据库线程的团队就和使用方团队就实现了所谓的解耦。

## CPU空闲时在干嘛

操作系统是用队列来管理进程的，那么很显然，如果队列已经为空，那么说明此时操作系统内部没有进程需要运行，这是 CPU 就空闲下来了，此时，我们需要做点什么，就像这样  

```
if (queue.empty()) {
	do_someting();
}
```

这些编写内核代码虽然简单，但内核中到处充斥着 if 这种异常处理的语句，这会让代码看起来一团糟，**因此更好的设计是没有异常**，那么怎样才能没有异常呢？

很简单，**那就是让队列永远不会空**，这样调度器永远能从队列中找到一个可供运行的进程。

而这也是为什么链表中通常会有哨兵节点的原因，就是为了避免各种判空，这样既容易出错也会让代码一团糟。

![image-20241103222552112](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241103222552112.png)

就这样，**内核设计者创建了一个叫做空闲任务的进程**，这个进程就是Windows 下的我们最开始看到的“系统空闲进程”，在 Linux 下就是第 0号进程。

当其它进程都处于不可运行状态时，调度器就从队列中取出空闲进程运行，显然，**空闲进程永远处于就绪状态，且优先级最低**。

CPU 设计者早就考虑到系统会存在空闲的可能，因此设计了一条机器指令，这个机器指令就是halt 指令，停止的意思。

这条指令会让部分CPU进入休眠状态，从而**极大减少对电力的消耗**，通常这条指令也被放到循环中执行，原因也很简单，就是要维持这种休眠状态。

值得注意的是，halt 指令是特权指令，也就是说只有在内核态下 CPU 才可以执行这条指令，程序员写的应用都运行在用户态，因此你没有办法在用户态让 CPU 去执行这条指令。

此外，不要把进程挂起和 halt 指令混淆，当我们调用 sleep 之类函数时，暂停运行的只是进程，此时如果还有其它进程可以运行那么 CPU 是不会空闲下来的，当 CPU 开始执行halt指令时就意味着系统中所有进程都已经暂停运行。

# 编译器是如何工作的

假定我们有一段程序：  

```
while (y < z) {
    int x = a + b;
    y += x;
}
```

那么编译器是怎样把这一段程序人类认识的程序转换为CPU认识的二进制机器指令呢？

## 1. 提取出每一个单词：词法分析

首先编译器要把源代码中的每个“单词”提取出来，在编译技术中“单词”被称为**token**。其实不只是每个单词被称为一个token，除去单词之外的比如左括号、右括号、赋值操作符等都被称为token。

从源代码中提取出token的过程就被称为词法分析，Lexical Analysis。经过一遍词法分析，编译器得到了以下token：  

```
T_While while
T_LeftParen （
T_Identifier y
T_Less <
T_Identifier z
T_RightParen )
T_OpenBrace {
T_Int int
T_Identifier x
T_Assign =
T_Identifier a
T_Plus +
T_Identifier b
T_Semicolon ;
T_Identifier y
T_PlusAssign +=
T_Identifier x
T_Semicolon ;
T_CloseBrace }
```

## 2. 这些token想表达什么意思：语法分析  

有了这些token之后编译器就可以根据语言定义的语法恢复其原本的结构，怎么恢复呢？  

原来，编译器在扫描出各个token后根据规则将其用树的形式表示出来，这颗树就被称为**语法树**。  

![image-20241103223151818](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20241103223151818.png)

## 3. 语法树是不是合理的：语义分析  

有了语法树后我们还要检查这棵树是不是合法的，比如我们不能把一个整数和一个字符串相加、比较符左右两边的数据类型要相同，等等。

这一步通过后就证明了程序合法，不会有编译错误。

![image-20241103223227008](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20241103223227008.png)

## 4. 根据语法树生成中间代码：代码生成

语义分析之后接下来编译器遍历语法树并用另一种形式来表示，用什么来表示呢？那就是中间代码， intermediate representation code，简称**IR code**。

上述语法树可能就会表示为这样的中间代码：

```
Loop: x = a + b
    y = x + y
    _t1 = y < z
    if _t1 goto Loop
```

## 5. 中间代码优化  

在生成中间代码后要对其进行优化，我们可以看到，实际上可以把x = a + b这行代码放到循环外，因为每次循环都不会改变x的值，因此优化后就是这样了：  

```
	x = a + b
Loop: y = x + y
    _t1 = y < z
    if _t1 goto Loop
```

中间代码优化后就可以生成机器指令了  

## 6. 代码生成

将上述优化后的中间代码转换为机器指令：

```
	add $1, $2, $3
Loop: add $4, $1, $4
	slt $6, $1, $5
	beq $6, loop
```

最终，编译器将程序员认识的代码转换为了CPU认识的机器指令。  

# 指令集

CPU的能力圈有一个特殊的名字，叫做 Instruction Set Architecture ，ISA，也就是**指令集**，指令集中包含各种各样的指令。指令集告诉我们一个CPU可以干嘛。

你从ISA中找一条指令发给CPU，CPU就是完成这条指令所代表的任务。

指令集是CPU告诉程序员该怎么让自己工作的。

**不同的CPU会有不同类型的指令集**，**指令集的类型除了影响程序员写汇编程序之外还会影响CPU的硬件设计**，到底CPU该采用什么类型的指令集，CPU该如何设计，这一论战持续至今，并且愈发精彩

## 复杂指令集CISC

### 指令使用方便

最先诞生的指令集类型：复杂指令集，Complex Instruction Set Computer，简称CISC。当今普遍存在于桌面PC以及服务器端的x86架构就是基于复杂指令集CISC

1970s年代，这一时期编译器还非常菜，不像现在这么智能，没多少人信得过编译器，**大部分程序还是用汇编语言纯手工编写** (这一点极为重要，对于接下来理解复杂指令集非常关键)，因此**大家普遍认为指令集应该更加丰富一些、指令本身功能更强大一些**，程序员常用的操作最好都有对应的特定指令，大家认为高级语言中的一些概念比如函数调用、循环控制、复杂的寻址模式、数据结构和数组的访问等都应该直接有对应的机器指令，这些就是现代大家认为的复杂指令集CISC非常鲜明的特点。

### 存储

除了更方便的使用汇编语言写程序，另一点需要考虑就是存储。代码是要占据存储空间的，要知道在1970s年代，内存大小仅仅数KB到数十KB，几KB的内存，可谓寸土寸金，**这么小的内存要想装入更多的程序就必须仔细的设计机器指令以节省程序占据的空间**，这就要求：

1. 一条机器指令尽可能完成更多的任务，这很容易理解，就像喝水例子一样，你更希望有一条“给我端杯水”的指令，而不是自己去写“迈出左脚；停住；迈出右脚；直到饮水机；伸出右手；拿起水杯；接水。。。”等等这样的汇编代码

2. 机器指令长度不固定，也就是变长机器指令，简单的指令占据更少的空间

3. 机器指令高度编码(encoded)，提高代码密度，节省空间



> 基于对程序员方便编写汇编语言以及节省代码存储空间的需要，直接促成了复杂指令集的设计，因此我们可以看到复杂指令集是这一时期必然的选择，该指令集就这样诞生了并开始成为主流。
>
> 就这样经过一段时间后，人们发现了新的问题，由于单条指令比较复杂，设计解码机器指令的硬件(CPU的一部分)成了一件非常麻烦的事情，该怎样解决这一问题呢？

对于指令集中的每一条机器指令都有一小段对应的程序，这些程序存储在CPU中，**这些程序都是由更简单的指令组成**，这些指令就是所谓的微代码，Microcode。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya1iaJTwNCcKiabgvBPD42JxucciauhK4r0Feo3klp8oyQic2wkUOaHVjuCicrWka5acZ4yT1icx7PAOXAng/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



就这样CPU的指令集可以添加更多的指令，代价仅仅是再多一些简单的微代码而已，是不是很天才的设计。

在这里也可以看到，一般我们认为CPU直接执行机器指令，严格来说这是不正确的，对于含有微代码设计的CPU来说，CPU直接执行的并不是机器指令，而是微代码，微代码是CPU以及机器指令的中间层，**机器指令相对于微代码来说是“更高级的语言”，机器指令对程序员来说可见，但微代码对程序员来说不可见，程序员无法直接使用微代码来控制CPU**。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya1iaJTwNCcKiabgvBPD42Jxucl5qD8Anvv67VEic6ic4UxYaV8UfqA9mHkCbHlMK520nstcnq7IkhRibsA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

在这一时期，这些微代码普遍存放在ROM中，Read-Only Memory，而ROM普遍要比内存便宜，因此依靠存储在ROM中的微代码来设计更多复杂指令进而减少程序本身对内存的占用是非常划算的。

### 精简指令集

>一切看上去都很好，有了复杂指令集，程序员可以更方便的编写汇编程序，这些程序也不需要占用很多存储空间，代价就是CPU中需要有微代码来简化CPU设计。
>
>然而这一设计随着时间的推移又出现了新的问题。
>
>作为程序员我们知道代码难免会有bug，微代码也不会有例外。但修复微代码的bug要比修复普通程序的bug困难的多，你无法像普通程序那样来测试、调试微代码，这一切都太复杂了。
>
>而且微代码设计非常消耗晶体管，1979年代的Motorola 68000 处理器就采用该设计，其中三分之一的晶体管都用在了微代码上。

#### 两个趋势

- 1980s年代，此时容量“高达”64K的内存开始出现，内存容量上终于不再捉襟见肘，价格也开始急速下降，在1977年，1MB内存的价格高达**$5000**，要知道这可是1977年的5000刀，但到了1994年，1MB内存价格就急速下降到大概只有$6，这是第一个趋势。

- 此外在这一时期随着编译技术的进步，编译器越来越成熟，**渐渐的程序员们开始依靠编译器来生成汇编指令而不再自己手工编写**。

大概80%的时间CPU都在执行那20%的机器指令，同时CISC中一部分比较复杂的指令并不怎么被经常用到，而且那些**设计编译器的程序员也更倾向于组合一些简单的指令来完成特定任务。**

复杂指令集中那些被认为可以提高性能的指令其实在内部被微代码拖后腿了，如果移除掉微代码，程序反而可以运行的更快，并且可以节省构造CPU消耗的晶体管数量。

#### 精简指令集的特点

**1. 指令本身的复杂度**

**精简指令集思想不是说指令集中指令的数量变少，而是说一条指令背后代表的动作更简单了**。

举个简单的例子，复杂指令集中的一条指令背后代表的含义是“吃饭”的全部过程，而精简指令集中的一条指令仅仅表示“咀嚼一下”的其中一个小步骤。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya12ltUymX3TQqpBNV7EhMcySDa83ZSlHPLnmsafM68EYYLxfE3Fblhxx23ps9avicNcO3bXibVm23yQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**2. 编译器**

精简指令集的另一个特点就是编译器对CPU的控制力更强。

在复杂指令集下，CPU会对编译器隐藏机器指令的执行细节，就像微代码一样，编译器对此无能为力。

而在精简指令集下CPU内部的操作细节暴露给编译器，编译器可以对其进行控制，也因此，精简指令集RISC还有一个有趣的称呼：“**R**elegate **I**nteresting **S**tuff to **C**ompiler”，把一些有趣的玩意儿让编译器来完成。

**3. load/store architecture** 

在复杂指令集下，一条机器指令可能涉及到从**内存**中取出数据、执行一些操作比如加和、然后再把执行结果写回到内存中，注意这是在一条机器指令下完成的。

但在精简指令集下，这绝对是大写的禁忌，**精简指令集下的指令只能操作寄存器中的数据**，不可以直接操作内存中的数据，也就是说这些指令比如加法指令不会去访问内存。

![图片](https://mmbiz.qpic.cn/mmbiz_png/8g3rwJPmya12ltUymX3TQqpBNV7EhMcyaTUmS8YAejM93sc6xgDjZq75M5vYuzejCmrU2MYcr04M3FBr9DegrA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

> 这些指令都非常简单，CPU内部不需要复杂的硬件逻辑来进行解码，因此更节省晶体管，这些节省下来的晶体管可用于其它功能上。
>
> 最关键的是，注意，由于每一条指令都很简单，执行的时间都差不多，因此这使得一种能高效处理机器指令的方法成为可能，这项技术是什么呢？这就是有名的**流水线技术**。**如果流水线每个阶段的耗时不同，将显著影响流水线的处理能力**。
>
> 精简指令集的设计者们当然也明白这个道理，因此**他们尝试让每条指令执行的时间都差不多一样**，尽可能让流水线更高效的处理机器指令，而这也是为什么在精简指令集中存在Load和Store两条访问内存指令的原因。

## 指令流水线

![image-20241105223218844](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241105223218844.png)

### 分支预测
程序员在代码中编写的 if 语句一般会被编译器翻译成一条跳转指令，
if 语句其实起到一种分支的作用，如果条件成立则需要执行if内部的逻辑，否则不执行；因此跳转指令会依赖自身的执行结果来决定到底要不要跳转，这会对流水线产生影响。

跳转指令需要依赖自身的执行结果来决定到底要不要跳转，那么在跳转指令没有执行完的情况下 CPU怎么知道后面哪个分支的指令能进入到流水线呢？  

![image-20241105223406215](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241105223406215.png)

CPU 会猜一下 if 语句可能会走哪个分支，如果猜对了流水线照常继续，如果猜错了，对不起，**流水线上已经执行的后续指令全部作废**，因此我们可以看到如果CPU猜错了会有性能损耗。

现代 CPU 将“猜”的这个过程称为**分支预测**，当然，CPU 中的分支预测并不是简单的抛硬币式的随机瞎猜，而且有特定策略，比如可能会基于执行跳转指令的历史去进行预测等等。

> eg:
>
> ```
> if (arr[i] >= 256) { sum += arr[i];}  
> ```
>
> CPU 在执行完跳转指令之前必须决定后续哪个分支的指令会进入到流水线，猜对了流水线照常进行，猜错了有性能损耗。
>
> 那么如果一个数组是有序的：
>
> ![image-20241106212341323](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241106212341323.png)
>
> 而如果一个数组是无序的：  
>
> ![image-20241106212354410](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241106212354410.png)
>
> 如果你给CPU一个无序数组，那么 Arr[i] 是否大于256 基本上就是随机的，对于随机事件，不要说CPU的分支预测，任何其它预测手段都将无效，否则这就不是随机事件了。
>
> 如果 CPU 猜的不对，那么流水线上的后续指令将作废，这就解释了为什么处理有序数组要比处理无序数组性能好了，因为在数组有序的情况下，CPU 
>
> 的分支预测几乎不会猜错，流水线上的指令不会被频繁作废。
>
> 这对程序员的启示就是：如果你编写了 if 语句，那么**你最好让** **CPU** **大概率能猜对**。



# mmap

虚拟内存就是假的**地址空间**，是进程看到的幻象，其目的是**让每个进程都认为自己独占内存**，那么既然是假的地址空间，显然就必须有什么东西能把这些假的地址转换为真的，这就是CPU内部MMU的作用，当CPU执行内存读写指令时，**MMU**会把这个假的地址转换为真实的物理内存地址。  

既然进程看到地址空间是假的那么一切都好办了。既然是假的，那么就有做手脚的操作空间，怎么做手脚呢？

从普通程序员眼里看文件不是保存在一段连续的磁盘空间上吗？我们可以直接把这段空间映射到进程的内存中，就像这样：  

![image-20241106212549633](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241106212549633.png)

假设文件长度是100字节，我们把该文件映射到了进程的内存中，地址是从600 ~ 800，那么当你直接读写600 ~ 800这段内存时，实际上就是在直接操作磁盘文件。  

当我们首次读取600~800这段地址空间时，操作系统会检测的这一操作，因为此时这段内存中什么内容都还没有，此时操作系统自己读取磁盘文件填充到这段内存空间中，此后程序就可以像读内存一样直接读取磁盘内容了。

写操作也很简单，用户程序依然可以直接修改这块内存，此后操作系统会在背后将修改内容写回磁盘。

现在你应该看到了，其实采用mmap这种方法磁盘依然还是按照块的粒度来寻址的，只不过在操作系统的一番骚操作下对于用户态的程序来说“看起来”我们能像读写内存那样直接读写磁盘文件了，从按块粒度寻址到按照字节粒度寻址，这中间的差异就是操作系统来填补的。

## 节省系统调用

我们常用的标准IO，也就是read/write其底层是涉及到系统调用的，同时当使用read/write读写文件内容时，需要将数据从内核态copy到用户态，修改完毕后再从用户态copy到内核态，显然，这些都是有开销的。  

![image-20241106212716577](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241106212716577.png)

而mmap则无此问题，基于mmap读写磁盘文件不会招致系统调用以及额外的内存copy开销，但mmap也不是完美的，mmap也有自己的缺点。  

其中一方面在于为了创建并维持地址空间与文件的映射关系，内核中需要有特定的数据结构来实现这一映射，这当然是有性能开销的，除此之外另一点就是缺页问题，page fault。

用mmap将文件映射到进程地址空间后，当我们引用的一段其对应的文件内容还没有真正加载到内存后就会产生中断，这个中断就是缺页，page fault，操作系统检测到这一信号后把相应的文件内容加载到内存。

注意，缺页中断也是有开销的，而且不同的内核由于内部的实现机制不同，其系统调用、数据copy以及缺页处理的开销也不同，因此就性能上来说我们不能肯定的说mmap就比标准IO好。这要看标准IO中的系统调用、内存调用的开销与mmap方法中的缺页中断处理的开销哪个更小，开销小的一方将展现出更优异的性能。

## 大文件处理

另一个优点在于mmap其实是和操作系统中的虚拟内存密切相关的，这就为mmap带来了一个很有趣的优势。

这个优势在于处理大文件场景，这里的大文件指的是文件的大小超过你的物理内存，在这种场景下如果你使用传统的read/write，那么你必须一块一块的把文件搬到内存，处理完文件的一小部分再处理下一部分。

这种需要在内存中开辟一块空间——也就是我们常说的buffer，的方案听上去就麻烦有没有，而且还需要操作系统把数据从内核态copy到用户态的buffer中。

但如果用mmap情况就不一样了，只要你的进程地址空间足够大，可以直接把这个大文件映射到你的进程地址空间中，即使该文件大小超过物理内存也可以，这就是虚拟内存的巧妙之处了**，当物理内存的空闲空间所剩无几时虚拟内存会把你进程地址空间中不常用的部分扔出去**，这样你就可以继续在有限的物理内存中处理超大文件了，这个过程对程序员是透明的，程序员根本就意识不要，虚拟内存都给你处理好了。

## 节省内存

假设有一个文件，很多进程的运行都依赖于此文件，而且还是有一个特定，那就是这些进程是以只读(read-only)的方式依赖于此文件。

你一定在想，这么神奇？很多进程以只读的方式依赖此文件？有这样的文件吗？

答案是肯定的，这就是动态链接库。

> mmap操作虚拟内存的文件映射区，文件映射区中包含动态链接库

### 动态链接库

#### 静态库

假设有三个程序A、B、C依赖一个静态库，那么链接器在生成可执行程序A、B、C时会把该静态库copy到A、B、C中，就像这样：  

![image-20241106213145626](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241106213145626.png)

假设你本身要写的代码只有2MB大小，但却依赖了一个100MB的静态库，那么最终生成的可执行程序就是102MB，尽管你本身的代码只有2MB。

而且从图中我们可以看出，可执行程序A、B、C中都有一部分静态库的副本，这里面的内容是完全一样的，那么很显然，这些可执行程序放在磁盘上会浪费磁盘空间，加载到内存中运行时会浪费内存空间。

那么该怎么解决这个问题呢？

很简单，可执行程序A、B、C中为什么都要各自保存一份完全一样的数据呢？其实我们只需要在可执行程序A、B、C中保存一小点信息，这点信息里记录了依赖了哪个库，那么当可执行程序运行起来后再吧相应的库加载到内存中：

![](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241106213224496.png)

依然假设你本身要写的代码只有2MB大小，此时依赖了一个100MB的动态链接库，那么最终生成的可执行程序就是2MB，尽管你依赖了一个100MB的库。

而且从图中可以看出，此时可执行程序ABC中已经没有冗余信息了，这不但节省磁盘空间，而且节省内存空间，**让有限的内存可以同时运行更多的进程**，是不是很酷。

#### 动态库

现在我们已经知道了动态库的妙用，但我们并没有说明动态库是怎么节省内存的，接下来mmap就该登场了。

你不是很多进程都依赖于同一个库嘛，那么我就用mmap把该库直接映射到各个进程的地址空间中，**尽管每个进程都认为自己地址空间中加载了该库，但实际上该库在内存中只有一份**。

![image-20241106213350449](https://raw.githubusercontent.com/qhbsss/Pictures/main/Blog_Picturesimage-20241106213350449.png)

mmap就这样很神奇和动态链接库联动起来了。  

# 标准库

记得当年在学了C/C++语言后一直有这样的疑惑，常用的printf函数以及C++中的cout函数到底是在哪里实现的？  

## C/C++语言是怎样实现的

有的同学一定觉得编程语言是十分神秘的，实际上不是这样的。一门编程语言的本质是什么？

本质上一门语言不过就是一堆规则(rules)而已，就像汉语中的主谓宾一样，就像

- if之后必须是一个括号()，这个括号中必须是一个bool

- 表达式while之后必须是一个括号()，这个括号中必须是一个bool

- 表达式continue语言必须出现在while语句中
- 等等

有的同学可能会问，为什么一定要有这堆规则呢，原来，只有有了规则之后编译器才能知道该怎么处理我们写的程序。

实际上C/C++以及任何一门编程语言都是这样的一堆规则，对于C/C++来说，每年都有一群来自被称为International Organization for Standardization (ISO)组织的人来制定C/C++语言的规则，因此这群人坐下来讨论的这堆规则实际上就是一个**标准**，每一次讨论都会重新修改制定新的标准并对外发布，这就是为什么C/C++有各种版本： C99, C11, C++03, C++11, C++14等等，其中的数字其实就是来自指定标准的年份。

对外发布的标准中包含两部分内容：

1. C/C++支持哪些特性

2. C/C++API，程序员可以在他们的C/C++程序中直接调用这些API，这些API就被称为

标准库(Standard Library)注意发布的标准中只定义了API，但是并不包括实现，肯定有同学会问，那么是谁来实现标准中定义的API呢？

## C/C++标准库的实现

至此，我们终于可以开始讨论标准库的实现问题了，实际上专门有一群人负责来根据发布的API来实现标准库，程序员在实现除了一些比如数学计算之外，像文件读写、内存分配、线程创建等等相关的API的实现，这些程序员必须借助相应操作系统提供的功能，那么这些程序是怎样使用操作系统提供的功能的呢？答案就是借助系统调用(System Call)，注意很多同学可能意识这一点，但是这一点相当重要，那就是我们所写的代码有很多是需要依赖操作系统的，操作系统其实提供了很多功能，程序员使用这些功能的方式其实就是借助系统调用  。

因此我们知道，其实每一个平台(操作系统)上都有自己特定的标准库实现，因为不同的操作系统提供的功能是不同的，提供的系统调用也是不同的。

现在我们就可以回答最开始提出的问题了，原来printf和cout等等的代码是实现在标准库中，那么这些标准库在哪里呢，我们的程序又是怎么用到标准库的呢？

## 标准库在哪里？怎样使用？  

eg:

```
#include <stdio.h>
    int main() {
    printf("hello world\n");
    return 0;
}
```

然后编译、执行：  

```
$ gcc helloworld.c -o hw
$ ./hw
hello world
```

编译可执行程序中的一个过程：链接。简单来说，链接的作用就是把程序依赖的各个库打包起来。要想看到可执行程序依赖哪些库，我们借助一个叫ldd的工具  

```
$ ldd hw
    linux-vdso.so.1 => (0x00007ffe075d3000)
    libc.so.6 => /usr/lib64/libc.so.6 (0x00007fcd58b75000)
    /lib64/ld-linux-x86-64.so.2 (0x000055c5dbea4000)
```

我们注意到可执行程序hw依赖一个叫做libc.so.6的库，位于/usr/lib64/libc.so.6，**这个****libc.so.6****就是我们苦苦寻找的标准库**。

Linux中以.so结尾的文件被称为动态链接库，难怪我们看不到标准库的实现

现在我们知道了标准库是什么，在哪里，有的同学可能会问，那么我们是怎么用标准库的呢？

原来，**编译器**gcc**在编译程序是默认情况下就自动链接了标准库**，因为大家写程序免不了使用标准库提供的API，因此gcc等编译器自动把标准库打包到了可执行程序了。

## Linux标准库实现

Linux下标准库的实现被称为GNU C Library，也被称为glibc，这个名字肯定有同学听过。

glibc是Linux平台中使用最为广泛的，然而有一段时间Linux发行版中的标准库多使用Libc，在经过了数年的开发后glibc又开始优于了Libc，Linux发行版又开始转回了glibc，现在在Linux发行版上你会看到磁盘上有一个libc.so.6的文件，这个文件其实就是现代版的glibc，只不过名字遵从了Linux发行版的习惯。

关于C++的标准库实现在了 libstdc++，你在Linux平台中使用ldd工具就能看到这个标准库。

## Windows标准库实现

Windows标准库实现是和微软的官方编译器Visual Studio绑定在一起的，该标准库曾被称为C/C++ Run-time Library (CRT)

从Windows95开始，微软以MSVCRT+版本号.DLL的命名实行来发布，到了1997年，将其简化为了MSVCRT.DLL。

从Visual Studio 2015之后，Windows中C/C++标准库被称为了Universal C Runtime Library (Universal CRT，简称UCRT)，即UCRTBASE.DLL，此后Windows标准库开始同Win10一起发布。
